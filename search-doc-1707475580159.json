{"searchDocs":[{"title":"Long Blog Post","type":0,"sectionRef":"#","url":"/blog/long-blog-post/","content":"This is the summary of a very long blog post, Use a &lt;!-- truncate --&gt; comment to limit blog post size in the list view. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet","keywords":"","version":null},{"title":"First Blog Post","type":0,"sectionRef":"#","url":"/blog/first-blog-post/","content":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet","keywords":"","version":null},{"title":"MDX Blog Post","type":0,"sectionRef":"#","url":"/blog/mdx-blog-post/","content":"Blog posts support Docusaurus Markdown features, such as MDX. tip Use the power of React to create interactive blog posts. &lt;button onClick={() =&gt; alert(&quot;button clicked!&quot;)}&gt;Click me!&lt;/button&gt; Click me!","keywords":"","version":null},{"title":"Welcome","type":0,"sectionRef":"#","url":"/blog/welcome/","content":"Docusaurus blogging features are powered by the blog plugin. Simply add Markdown files (or folders) to the blog directory. Regular blog authors can be added to authors.yml. The blog post date can be extracted from filenames, such as: 2019-05-30-welcome.md2019-05-30-welcome/index.md A blog post folder can be convenient to co-locate blog post images: The blog supports tags as well! And if you don't want a blog: just delete this directory, and use blog: false in your Docusaurus config.","keywords":"","version":null},{"title":"Installation","type":0,"sectionRef":"#","url":"/docs/getting_started/","content":"","keywords":"","version":"Next"},{"title":"NPM​","type":1,"pageTitle":"Installation","url":"/docs/getting_started/#npm","content":" If you don't already have nodejs installed, you can find the instructions here. Install Tailcall by running the following command in your terminal: npm i -g @tailcallhq/tailcall Verify that Tailcall is installed correctly by running: tailcall note Do not use the --force flag during npm installations, as it ignores installing platform-specific builds.  ","version":"Next","tagName":"h2"},{"title":"Yarn​","type":1,"pageTitle":"Installation","url":"/docs/getting_started/#yarn","content":" Install Tailcall by running the following command in your terminal: yarn global add @tailcallhq/tailcall Verify that Tailcall is installed correctly by running: tailcall   ","version":"Next","tagName":"h2"},{"title":"Homebrew​","type":1,"pageTitle":"Installation","url":"/docs/getting_started/#homebrew","content":" If you don't already have Homebrew installed, you can find the instructions here. Add the Tailcall repository to Homebrew by running the following command in your terminal: brew tap tailcallhq/tailcall brew install tailcall Verify that Tailcall is installed correctly by running: tailcall Once installation is done, upgrades can be performed via: brew update brew upgrade tailcall   ","version":"Next","tagName":"h2"},{"title":"Curl​","type":1,"pageTitle":"Installation","url":"/docs/getting_started/#curl","content":" Follow the steps below to manually install the cli on your system:  curl -sSL https://raw.githubusercontent.com/tailcallhq/tailcall/master/install.sh | bash -s --   This command fetches and executes the Tailcall installation script. The installed files are located in the ~/.tailcall directory.  Upon completion of the installation, extend your PATH environment variable to include the ~/.tailcall/bin directory:  export PATH=$PATH:~/.tailcall/bin   ","version":"Next","tagName":"h2"},{"title":"Docker​","type":1,"pageTitle":"Installation","url":"/docs/getting_started/#docker","content":" If you want to install Tailcall with Docker, follow the steps below. Before starting, ensure Docker is installed on your system. If not, you can download it from here.  Pull the latest Tailcall Docker image using the following command: docker pull tailcall.docker.scarf.sh/tailcallhq/tailcall/tc-server: This command fetches the latest version of the Tailcall Docker image from the Docker registry. Run the Tailcall Docker container with the following command: docker run -p 8080:8080 -p 8081:8081 tailcall.docker.scarf.sh/tailcallhq/tailcall/tc-server: This command starts the Tailcall server in a Docker container. Similar to the homebrew installation, it exposes a the graphQL endpoint on port 8080. ","version":"Next","tagName":"h2"},{"title":"Problem Statement","type":0,"sectionRef":"#","url":"/docs/","content":"","keywords":"","version":"Next"},{"title":"Traditional API Gateway​","type":1,"pageTitle":"Problem Statement","url":"/docs/#traditional-api-gateway","content":" Traditional API Gateways (&quot;TAGs&quot;) form the backbone of modern web based application architectures, offering a comprehensive suite of features essential for efficient API management. These gateways handle tasks such as routing, authentication, circuit breaking, caching, logging, monitoring, protocol translation and the list doesn't end!  However, API Gateways don't provide developers access to the right abstraction when it comes to configuring these capabilities. Typically a TAG would provide you with primitives that are based on the underlying protocol (i.e. the protocol on which the API is served). For example: you can perform authentication, routing, rate-limiting etc. on the basis of the request headers, URL or method. All of which are components of the HTTP protocol. This happens because they treat the contents of request and response bodies as mere byte sequences, without delving into their substance.  Over the years, we have gotten used to consuming and managing APIs this way. Writing our own custom abstractions and sticking it around an existing over the shelf API Gateway. Our personal experience has been that nearly all companies after a certain scale require an abstraction that's specific to their business entities and feel restricted by what the API Gateway can provide.  ","version":"Next","tagName":"h2"},{"title":"Tailcall API Gateway​","type":1,"pageTitle":"Problem Statement","url":"/docs/#tailcall-api-gateway","content":" Based on our learnings of writing APIs at massive scale, we believe that the gateway should work around an enterprise's business entities and not the other way round. That's exactly what Tailcall helps you achieve. Tailcall provides first-class primitives designed to interact with your business entities directly without burdening the developer with the underlying protocol. This approach grants tremendous power and flexibility, transcending protocol constraints and focusing on the nature of the API's data. Let's take the User entity as an example:  type User { id: ID name: String email: String account: Account } type Account { balance: Float lastUpdated: Date }   User is a business entity that can be resolved from multiple APIs. A /users API could resolve the id, name &amp; email and a /accounts/:userId could resolve the user's account balance and lastUpdated. With tailcall's API Gateway you will be able to specify that requests accessing the account details will require authentication, whereas other requests may not.  type User { id: ID name: String email: String account: Account @private } type Account { balance: Float lastUpdated: Date }   With Tailcall, specifying which parts of an entity should be public or private becomes straightforward, the platform also allows for the obfuscation of fields deemed sensitive or PII in specific contexts. This is all achievable through Tailcall's DSL, which facilitates all these complex operations efficiently and with minimal latency.  Further enhancing its capabilities, Tailcall's DSL supports sophisticated API Orchestration, going beyond mere request routing. It enables you to define the expected API structure and provides guidance on resolving each component within the entity type. For instance, consider a transaction API containing a userId. Traditionally, expanding this userId to retrieve the corresponding user details would require additional micro-services. However, with Tailcall, expressing this requirement through its DSL prompts the Tailcall runtime to automatically resolve and populate these details for you. This approach eliminates the need for any manual coding, streamlining the API management process significantly. ","version":"Next","tagName":"h2"},{"title":"Execute","type":0,"sectionRef":"#","url":"/docs/getting_started/execute/","content":"Execute Open a web browser and go to http://localhost:8000. This should load the GraphiQL interface. In the query editor of GraphiQL, enter the following query query { users { id name posts { title } } } After running the query in GraphiQL, expect to see a JSON response structured like this: { &quot;data&quot;: { &quot;users&quot;: [ { &quot;id&quot;: 1, &quot;name&quot;: &quot;Leanne Graham&quot;, &quot;posts&quot;: [ { &quot;title&quot;: &quot;sunt aut facere repellat provident occaecati excepturi option reprehenderit&quot; } // Additional posts truncated for brevity ] }, { &quot;id&quot;: 2, &quot;name&quot;: &quot;Ervin Howell&quot;, &quot;posts&quot;: [ { &quot;title&quot;: &quot;et ea vero quia laudantium autem&quot; }, { &quot;title&quot;: &quot;in quibusdam tempore odit est dolorem&quot; } // Additional posts truncated for brevity ] } // Additional users truncated for brevity ] } } You can now add additional fields, and compose more queries together!","keywords":"","version":"Next"},{"title":"Launch","type":0,"sectionRef":"#","url":"/docs/getting_started/launch/","content":"Launch Now, run the following command to start the server with the full path to the file that you created earlier. graphqlymljson tailcall start ./jsonplaceholder.graphql If the command succeeds, you should see logs like the following below. 🚀 Tailcall launched at [0.0.0.0:8000] 🌍 Playground: http://0.0.0.0:8000 The server starts with the schema provided and prints out a load of meta information. We will cover those in detail in a bit. For now, open the playground URL in a new tab in your browser and try it out for yourself!","keywords":"","version":"Next"},{"title":"CLI","type":0,"sectionRef":"#","url":"/docs/guides/cli/","content":"","keywords":"","version":"Next"},{"title":"check​","type":1,"pageTitle":"CLI","url":"/docs/guides/cli/#check","content":" The check command validates a composition spec. Notably, this command can detect potential N+1 issues. To use the check command, follow this format:  tailcall check [options] &lt;file&gt;...   The check command offers various options that control different settings, such as the display of the generated schema, n + 1 issues etc.  ","version":"Next","tagName":"h2"},{"title":"--n-plus-one-queries​","type":1,"pageTitle":"CLI","url":"/docs/guides/cli/#--n-plus-one-queries","content":" This flag triggers the detection of N+1 issues.  Type: BooleanDefault: false  tailcall check --n-plus-one-queries &lt;file&gt;...   ","version":"Next","tagName":"h3"},{"title":"--schema​","type":1,"pageTitle":"CLI","url":"/docs/guides/cli/#--schema","content":" This option enables the display of the schema of the composition spec.  Type: BooleanDefault: false  tailcall check --schema &lt;file1&gt; &lt;file2&gt; ... &lt;fileN&gt;   The check command allows for multiple files. Specify each file path, separated by a space, after the options.  Example:  tailcall check --schema ./path/to/file1.graphql ./path/to/file2.graphql   ","version":"Next","tagName":"h3"},{"title":"compose​","type":1,"pageTitle":"CLI","url":"/docs/guides/cli/#compose","content":" The compose merges multiple configuration files into one. To use the compose command, follow this format:  Example:  tailcall compose ./path/to/file1.graphql ./path/to/file2.graphql   ","version":"Next","tagName":"h2"},{"title":"--format​","type":1,"pageTitle":"CLI","url":"/docs/guides/cli/#--format","content":" This specifies the format of the desired composed file. It accepts gql or graphql,yml or yaml, json . Default is json.  tailcall compose ./path/to/file1.graphql ./path/to/file2.graphql --format gql   ","version":"Next","tagName":"h3"},{"title":"start​","type":1,"pageTitle":"CLI","url":"/docs/guides/cli/#start","content":" The start command launches the TailCall Server, acting as a GraphQL proxy with specific configurations. The server can publish various GraphQL configurations.  To start the server, use the following command:  tailcall start &lt;file1&gt; &lt;file2&gt; ... &lt;fileN&gt; &lt;http_path1&gt; &lt;http_path2&gt; .. &lt;http_pathN&gt;   The start command allows for multiple files and supports loading configurations over HTTP. You can mix file system paths with HTTP paths. Specify each path, separated by a space, after the options.  Example:  tailcall start ./path/to/file1.graphql ./path/to/file2.graphql http://example.com/file2.graphql   ","version":"Next","tagName":"h2"},{"title":"init​","type":1,"pageTitle":"CLI","url":"/docs/guides/cli/#init","content":" The init command bootstraps a new TailCall project. It creates the necessary GraphQL schema files in the provided file path.  tailcall init &lt;file_path&gt;   This command prompts for additional file creation and configuration, creating a .tailcallrc.graphql file by default. ","version":"Next","tagName":"h2"},{"title":"Configuration","type":0,"sectionRef":"#","url":"/docs/getting_started/configuration/","content":"Configuration For our first example, we are going to compose a GraphQL schema from the REST APIs at https://jsonplaceholder.typicode.com, a free online REST API with some fake data. We will use the API at /users to get a list of users, and /users/:id/posts to get the posts for each user, and compose them into a single GraphQL schema. We can use the following formats to define our GraphQL schema: .graphql, .yml, .json. Create one of the following files and paste the contents into it. graphqlymljson jsonplaceholder.graphql schema # Specify server configuration: Start tailcall server at 0.0.0.0:8000 and enable GraphiQL playground @server(port: 8000, graphiql: true) # Specify a base url for all http requests @upstream(baseURL: &quot;http://jsonplaceholder.typicode.com&quot;) { query: Query } type Query { # Specify the http path for the users query users: [User] @http(path: &quot;/users&quot;) } # Create a user type with the fields returned by the users api type User { id: Int! name: String! username: String! email: String! # Extend the user type with the posts field # Use the current user's id to construct the path posts: [Post] @http(path: &quot;/users/{{value.id}}/posts&quot;) } # Create a post type with the fields returned by the posts api type Post { id: Int! title: String! body: String! } The above file is a standard .graphQL file, with a few additions such as @upstream and @http directives. So basically we specify the GraphQL schema and how to resolve that GraphQL schema in the same file, without having to write any code!","keywords":"","version":"Next"},{"title":"Context","type":0,"sectionRef":"#","url":"/docs/guides/context/","content":"","keywords":"","version":"Next"},{"title":"Context in Tailcall​","type":1,"pageTitle":"Context","url":"/docs/guides/context/#context-in-tailcall","content":" In Tailcall, as in all GraphQL implementations, Context is a variable that is accessible to every Operator. It is used to store and access data that needs to be shared between operators.  The Context can be described using the following Typescript interface:  interface Context { args: Map&lt;string, Json&gt; value: Json parent: Context env: Map&lt;string, string&gt; headers: Map&lt;string, string&gt; }   ","version":"Next","tagName":"h2"},{"title":"args​","type":1,"pageTitle":"Context","url":"/docs/guides/context/#args","content":" These are the arguments passed to the current query. They can be used to access the arguments of the query. For example,  type Query { user(id: ID!): User @http(path: &quot;/users/{{args.id}}&quot;) }   In this example, args.id is used to access the id argument passed to the user query.  ","version":"Next","tagName":"h3"},{"title":"value​","type":1,"pageTitle":"Context","url":"/docs/guides/context/#value","content":" This represents the value of the current node. For instance,  type Post { id: ID! title: String! body: String! comments: [Comment] @http(path: &quot;/posts/{{value.id}}/comments&quot;) }   In the example above, value.id is used to access the id field of the Post type.  ","version":"Next","tagName":"h3"},{"title":"parent​","type":1,"pageTitle":"Context","url":"/docs/guides/context/#parent","content":" This denotes the context of the parent node.  type Query { posts: [Post] @http(path: &quot;/posts&quot;) } type Post { id: Int! userId: Int! title: String! body: String! user: User @http(path: &quot;/users&quot;, query: [{key: &quot;id&quot;, value: &quot;{{value.userId}}&quot;}], matchPath: [&quot;id&quot;], matchKey: &quot;userId&quot;) }   In this case, value.userId is a way to get the userId information from the &quot;parent&quot; context of the Post type. Essentially, it's extracting a list or &quot;array&quot; of userId fields from multiple Post types. Think of value as a container that holds the results of a post query, with userId being the specific key you want to fetch from that container.  ","version":"Next","tagName":"h3"},{"title":"env​","type":1,"pageTitle":"Context","url":"/docs/guides/context/#env","content":" This represents global environment variables for the server. This is set once when the server starts.  type Query { users: [User]! @http(baseUrl: &quot;{{env.API_ENDPOINT}}&quot;, path: &quot;/users&quot;) }   In the above example, env.API_ENDPOINT refers to an environment variable called API_ENDPOINT, which should be defined in your server settings.  ","version":"Next","tagName":"h3"},{"title":"headers​","type":1,"pageTitle":"Context","url":"/docs/guides/context/#headers","content":" These are the headers of the request that was received by the Tailcall server.  type Query { commentsForUser: [Comment] @http(path: &quot;/users/{{headers.userId}}/comments&quot;) }   Here, headers.userId refers to a header called userId that should be present in the context. The server can use this userId to fetch comments for the specified user. ","version":"Next","tagName":"h3"},{"title":"Environment Variables","type":0,"sectionRef":"#","url":"/docs/guides/environment-variables/","content":"","keywords":"","version":"Next"},{"title":"Need for Environment Variables​","type":1,"pageTitle":"Environment Variables","url":"/docs/guides/environment-variables/#need-for-environment-variables","content":" Applications use multiple external tools, authentication methods, and numerous configurations. Therefore, for proper functioning, our code needs to access these values correctly.  Consider a simple scenario of JWT authentication. Typically, when signing tokens for our users, we need the following configuration set:  Expiry time: The duration after which the token expires.Secret key: The key used to encrypt the token.Issuer: The name of the token issuer, usually the organization's name.  There are broadly two ways to manage this:  Hardcode the values in our code: This is the simplest but most dangerous and inefficient approach. Hardcoding values in your codebase exposes sensitive information to everyone who works on the code, posing a massive security risk. Also, changing these values requires code modification and application redeployment, which is not ideal. Store the values in environment variables: This is the preferred approach. Store sensitive values in the OS of the server running your application. During runtime, your application can access these values from the OS. All programming languages have excellent support for this. This method keeps sensitive information secure and allows value changes without code modifications.  ","version":"Next","tagName":"h2"},{"title":"Environment Variables in Tailcall​","type":1,"pageTitle":"Environment Variables","url":"/docs/guides/environment-variables/#environment-variables-in-tailcall","content":" With Tailcall, you can seamlessly integrate environment variables into your GraphQL schema. Tailcall supports this through a env Context variable. This Context is shared across all operators, allowing you to resolve values in your schema.  Let's take an example. Consider the following schema:  type Query { users: [User]! @http(baseUrl: &quot;https://jsonplaceholder.typicode.com&quot;, path: &quot;/users&quot;) }   Here, we fetch a list of users from the JSONPlaceholder API. The users field will contain the fetched value at runtime. This works fine, but what if we want to change the API endpoint? We would need to modify the code and redeploy the application, which is cumbersome.  We can address this issue using environment variables. Simply replace the API endpoint with an environment variable, allowing us to change the variable's value without altering our codebase.  type Query { users: [User]! @http(baseUrl: &quot;{{env.API_ENDPOINT}}&quot;, path: &quot;/users&quot;) }   Here, API_ENDPOINT is an environment variable that must be set on the device where your server runs. The server picks up this value at startup and makes it available in the env Context variable.  This approach allows us to change the API endpoint without modifying our codebase. For instance, we might use different API endpoints for development (stage-api.example.com) and production (api.example.com) environments.  Note that environment variables are not limited to the baseUrl or @http operator. Since evaluation is done via a Mustache template, you can use them anywhere in your schema.  Here's another example, using an environment variable in the headers of @grpc:  type Query { users: [User] @grpc( service: &quot;UserService&quot; method: &quot;ListUsers&quot; protoPath: &quot;./proto/user_service.proto&quot; baseURL: &quot;https://grpc-server.example.com&quot; headers: [{key: &quot;X-API-KEY&quot;, value: &quot;{{env.API_KEY}}&quot;}] ) }   ","version":"Next","tagName":"h2"},{"title":"Security Aspects and Best Practices​","type":1,"pageTitle":"Environment Variables","url":"/docs/guides/environment-variables/#security-aspects-and-best-practices","content":" Environment variables help mitigate many security risks. However, it's important to note that they don't eliminate risks entirely, as the values are still in plain text. While configuration values might not be highly sensitive, secrets can still be compromised.  To ensure your secrets remain secure, consider the following tips:  Use a .env file: A common practice is to create a .env file in your project's root directory to store all environment variables. This file should not be committed to your version control system and should be added to .gitignore. This approach ensures your secrets are not publicly exposed. Additionally, use a .env.example file to list all required environment variables for your application, informing other developers of the necessary variables. In Tailcall (or elsewhere), you can use this .env file by exporting its key-value pairs to your OS. For example, if your .env file looks like this: API_ENDPOINT=https://jsonplaceholder.typicode.com Export it to your OS with: export $(cat .env | xargs) On Windows, use: Get-Content .env | Foreach-Object { [System.Environment]::SetEnvironmentVariable($_.Split(&quot;=&quot;)[0], $_.Split(&quot;=&quot;)[1], &quot;User&quot;) } After this, you can access API_ENDPOINT in your codebase. Use Kubernetes Secrets: If deploying your application with Kubernetes, use its Secrets feature to store environment variables. This ensures your secrets are not publicly exposed and are not hardcoded in your codebase. It also simplifies value changes when needed. Store Secrets Through Cloud Provider GUIs: When using a cloud provider for deployment, utilize their GUI to store environment variables. These interfaces are usually intuitive and practical, especially for containerized applications that scale automatically.  By following these practices, you can effectively manage and secure your environment variables. ","version":"Next","tagName":"h2"},{"title":"Tuning Client for Performance","type":0,"sectionRef":"#","url":"/docs/guides/client-tuning/","content":"","keywords":"","version":"Next"},{"title":"HTTP (Hypertext Transfer Protocol)​","type":1,"pageTitle":"Tuning Client for Performance","url":"/docs/guides/client-tuning/#http-hypertext-transfer-protocol","content":" HTTP is like the most widely used protocol for communication between a client and a server. When you request a webpage, it's HTTP that carries your request to the server and then brings back the data to your client. HTTP is built on top of TCP.  ","version":"Next","tagName":"h3"},{"title":"HTTP Versions: 1.x, 2, and 3​","type":1,"pageTitle":"Tuning Client for Performance","url":"/docs/guides/client-tuning/#http-versions-1x-2-and-3","content":" With each version, HTTP has become more flexible and performant.  HTTP/1.x: Each HTTP request creates separate TCP connection (or a sequentially reused one).HTTP/2: Introduces multiplexing, allowing multiple requests and responses to be sent concurrently over a single TCP connection, improving performance.HTTP/3: Uses QUIC instead of TCP, further reducing connection setup time and improving handling of packet loss and network changes.  note The version of the HTTP is decided by the server. So if the server only supports HTTP/1 there is no way the client can make an HTTP/2 request, even if it's compatible. However if the client only supports HTTP/1 the server as per the spec should respect and downgrade itself to serve the request over HTTP/1.  ","version":"Next","tagName":"h3"},{"title":"TCP (Transmission Control Protocol)​","type":1,"pageTitle":"Tuning Client for Performance","url":"/docs/guides/client-tuning/#tcp-transmission-control-protocol","content":" TCP is the underlying protocol that makes sure the data sent and received over the internet reaches its destination correctly and in order.  Before any data can be exchanged using HTTP, TCP establishes a connection between the client and server, like dialing a number before talking on the phone. We will see how to tune Tailcall's HTTP client to improve the performance of this connection. You can learn more about TCP in detail here.  ","version":"Next","tagName":"h3"},{"title":"QUIC (Quick UDP Internet Connections)​","type":1,"pageTitle":"Tuning Client for Performance","url":"/docs/guides/client-tuning/#quic-quick-udp-internet-connections","content":" QUIC is a newer protocol developed by Google. It's designed to make web communications faster and more efficient compared to TCP. It reduces connection establishment time, is better at handling packet loss, and supports multiplexed streams over a single connection, which prevents one slow request from holding up others. It is the foundation for HTTP/3. You can learn more about QUIC in detail here.  ","version":"Next","tagName":"h3"},{"title":"Why Managing Connections is Important?​","type":1,"pageTitle":"Tuning Client for Performance","url":"/docs/guides/client-tuning/#why-managing-connections-is-important","content":" Performance Overhead: Establishing TCP connections, particularly in HTTP/1.x, can be time consuming due to the need for a complete TCP handshake for each new connection. This process adds latency and increase in system resources . Limited Ports on Client Side: Each TCP connection from a client requires a unique combination of an IP address and a port number. With each new connection the IP remains the same because the client is the same, however a new port is used. The number of available ports on a machine is 65535, they are shared between all the processes and not all are available for usage. So this excessive creation of new connections ultimately leads to port exhaustion on the client side, preventing it from establishing new connections and causing system failures across the processes that are running on the system. tip You can check out the ports to process mapping using lsof and netstat commands.  Connection pooling helps mitigate the above issues by reusing existing connections for multiple requests. This reduces the frequency of connection establishments (and thus the handshake overhead) and also conserves client-side ports. This approach enhances application performance by minimizing the resources and time spent on managing connections.  ","version":"Next","tagName":"h3"},{"title":"Tuning HTTP Client​","type":1,"pageTitle":"Tuning Client for Performance","url":"/docs/guides/client-tuning/#tuning-http-client","content":" Tailcall by default uses connection pooling to manage connections and is setup with a default tuning which works well for most of the use cases. However, there are some cases where you might want to tune the HTTP client further to improve the performance of your application. Tailcall DSL provides an operator named @upstream which can help you to tune the HTTP client.  note The connection pooling is only a meaning optimization when it comes to HTTP/1. Since HTTP/2 and HTTP/3 support multiplexing it's hard to see any observable difference in performance with pooling enabled.  When using HTTP/1.x, you can tune the connection pool by using the following parameters:  ","version":"Next","tagName":"h2"},{"title":"poolMaxIdlePerHost​","type":1,"pageTitle":"Tuning Client for Performance","url":"/docs/guides/client-tuning/#poolmaxidleperhost","content":" poolMaxIdlePerHost is a setting that specifies the maximum number of idle connections allowed per host and defaults to 60. Example:  schema @upstream( poolMaxIdlePerHost: 60 ) { query: Query }   Keeping too many idle connections can unnecessarily tie up memory and ports, while too few might lead to delays as new connections have to be established frequently. By limiting the number of idle connections, poolMaxIdlePerHost ensures that the system uses network and memory resources judiciously, avoiding wastage on connections that are rarely used.  If you have an application which connects to many hosts you should set this value to a lower number that way you will have connections available to connect to other hosts. On the other hand if you a few hosts and all requests have to be resolved by those hosts, you should keep a higher value for this setting.  ","version":"Next","tagName":"h3"},{"title":"tcpKeepAlive​","type":1,"pageTitle":"Tuning Client for Performance","url":"/docs/guides/client-tuning/#tcpkeepalive","content":" tcpKeepAlive is a setting that keeps TCP connections alive for the specified duration, especially during periods of inactivity. It periodically sends packets to the server to check if the connection is still open and functioning. In connection pooling, where you have a set of reusable connections, tcpKeepAlive helps in maintaining these connections in a ready-to-use state. It's particularly useful for long-lived connections in the pool. By ensuring these connections are still active, it prevents the client from attempting to use a connection that has been closed by the server due to inactivity. Without tcpKeepAlive, idle connections in the pool might get silently dropped by the server or intermediate network devices (like firewalls or load balancers). When your client tries to use such a dropped connection, it would fail, causing delays and errors. Keeping connections alive and monitored means you can efficiently reuse them, reducing the overhead of establishing new connections frequently.  Tailcall provides a parameter named tcpKeepAlive for the upstream which defaults to 5 seconds. Example: schema  @upstream ( tcpKeepAlive: 300 ) { query: Query }   ","version":"Next","tagName":"h3"},{"title":"connectTimeout​","type":1,"pageTitle":"Tuning Client for Performance","url":"/docs/guides/client-tuning/#connecttimeout","content":" connectTimeout is a specific kind of timeout that applies only to the phase where your client is trying to establish a connection with the server. When you make a connection request client tries to resolve the DNS, have SSL handshake, and establish a TCP connection. In an environment where these pods are frequently created and destroyed, it's important to have a low connectTimeout to avoid unnecessary delays. In a system using connection pooling, If a connection can't be established within the connectTimeout period, the attempt is aborted. This prevents the client from waiting indefinitely for a connection to be established, which could lead to delays and timeouts.  Tailcall provides a parameter named connectTimeout which can be used to set the connection timeout in seconds for the HTTP client which defaults to 60 seconds. Example:  schema @upstream( connectTimeout: 10 ) { query: Query }   In summary, the key to maximizing HTTP client performance lies in understanding the underlying protocols and thoughtful configuration of client settings through test. By doing so, developers can ensure efficient, robust, and high-performing client-server communication, essential for the smooth operation of modern web applications. ","version":"Next","tagName":"h3"},{"title":"Logging","type":0,"sectionRef":"#","url":"/docs/guides/logging/","content":"","keywords":"","version":"Next"},{"title":"error​","type":1,"pageTitle":"Logging","url":"/docs/guides/logging/#error","content":" This is the highest severity level. It indicates a critical issue that may lead to the failure of the program or a part of it.  TAILCALL_LOG_LEVEL=error tailcall &lt;COMMAND&gt; # or TC_LOG_LEVEL=error tailcall &lt;COMMAND&gt;   ","version":"Next","tagName":"h3"},{"title":"warn​","type":1,"pageTitle":"Logging","url":"/docs/guides/logging/#warn","content":" This log level signifies potential issues or warnings that do not necessarily result in immediate failure but may require attention.  TAILCALL_LOG_LEVEL=warn tailcall &lt;COMMAND&gt; # or TC_LOG_LEVEL=warn tailcall &lt;COMMAND&gt;   ","version":"Next","tagName":"h3"},{"title":"info​","type":1,"pageTitle":"Logging","url":"/docs/guides/logging/#info","content":" This level offers general information about the program's execution, providing insights into its state and activities.  TAILCALL_LOG_LEVEL=info tailcall &lt;COMMAND&gt; # or TC_LOG_LEVEL=info tailcall &lt;COMMAND&gt;   ","version":"Next","tagName":"h3"},{"title":"debug​","type":1,"pageTitle":"Logging","url":"/docs/guides/logging/#debug","content":" The debug log level is useful for developers during the debugging process, providing detailed information about the program's internal workings.  TAILCALL_LOG_LEVEL=debug tailcall &lt;COMMAND&gt; # or TC_LOG_LEVEL=debug tailcall &lt;COMMAND&gt;   ","version":"Next","tagName":"h3"},{"title":"trace​","type":1,"pageTitle":"Logging","url":"/docs/guides/logging/#trace","content":" The trace log level is the most detailed logging level, used for fine-grained debugging. This level provides exhaustive details about the program's execution flow.  TAILCALL_LOG_LEVEL=trace tailcall &lt;COMMAND&gt; # or TC_LOG_LEVEL=trace tailcall &lt;COMMAND&gt;   ","version":"Next","tagName":"h3"},{"title":"off​","type":1,"pageTitle":"Logging","url":"/docs/guides/logging/#off","content":" This level serves as a special indicator for generating no logs, allowing the option to disable logging entirely.  TAILCALL_LOG_LEVEL=off tailcall &lt;COMMAND&gt; # or TC_LOG_LEVEL=off tailcall &lt;COMMAND&gt;   info By default, the log level is set to info.  Log levels are hierarchical, meaning if you set the log level to a specific level, it includes all the levels above it. For example, setting the log level to info will include logs at the info, warn, and error levels, but exclude debug and trace logs.    info Log levels are flexible and can be provided in either uppercase or lowercase. For instance, setting TAILCALL_LOG_LEVEL=DEBUG or TAILCALL_LOG_LEVEL=debug will yield the same result. ","version":"Next","tagName":"h3"},{"title":"Composition","type":0,"sectionRef":"#","url":"/docs/guides/operator-composition/","content":"Composition Operators can be composed and used together to create new and powerful transformations. This example illustrates the concept of composition in GraphQL, which allows you to combine multiple operations (known as &quot;operators&quot;) to build more complex transformations of data. The given schema is defining two data types - User and Post. The User type has fields id and name, and the Post type initially has fields user and userId. type User { id: Int name: String } type Post @addField(name: &quot;userName&quot;, path: [&quot;user&quot;, &quot;name&quot;]) { user: User @modify(omit: true) @http(path: &quot;/users/{{userId}}&quot;) userId: Int! } However, it uses a series of operators to modify the user field. The @addField(name: &quot;userName&quot;, path: [&quot;user&quot;, &quot;name&quot;]) operator is used to extract the name field from user and add a field called userName to the Post The @modify(omit: true) operator is used to remove the user field from the final Schema. The @http(path: &quot;/users/{{userId}}&quot;) operator is used to instruct the resolver to make an HTTP request to fetch the user data from a specified path (i.e., /users/{{userId}}), where {{userId}} is a placeholder that would be replaced with the actual userId when making the request. The schema after this transformation looks like this: type User { id: Int name: String } type Post { userName: String userId: Int! } So, we've used composition of operators to take a complex object (the User inside the Post), extract a specific part of it (name), name that part (userName), and then instruct GraphQL how to fetch the data using an HTTP request. info It is important to note that the order of the operators @modify and @http doesn't matter. The resulting schema will always be the same. This is a powerful mechanism that allows you to make your GraphQL schema more precise, easier to understand, and more suitable for the specific needs of your application.","keywords":"","version":"Next"},{"title":"Operators","type":0,"sectionRef":"#","url":"/docs/operators/","content":"Operators Tailcall DSL builds on your existing GraphQL knowledge by allowing the addition of some custom operators. These operators provide powerful compile time guarantees to make sure your API composition is tight and robust. The operator information is used to automatically generate highly optimized resolver logic for your types. Here is a list of all the custom operators supported by Tailcall: Certainly! Here's the table with hyperlinks added back to the operator names: Operator\tDescription@addField\tSimplifies data structures and queries by adding, inlining, or flattening fields or nodes within the schema. @cache\tEnables caching for the query, field or type it is applied to. @const\tAllows embedding of a constant response within the schema. @graphQL\tResolves a field or node by a GraphQL API. @grpc\tResolves a field or node by a gRPC API. @http\tResolves a field or node by a REST API. @modify\tEnables changes to attributes of fields or nodes in the schema. @server\tProvides server configurations for behavior tuning and tailcall optimization in various use-cases. @upstream\tControls aspects of the upstream server connection, including timeouts and keep-alive settings.","keywords":"","version":"Next"},{"title":"Tackling N + 1","type":0,"sectionRef":"#","url":"/docs/guides/n+1/","content":"","keywords":"","version":"Next"},{"title":"Scenario​","type":1,"pageTitle":"Tackling N + 1","url":"/docs/guides/n+1/#scenario","content":" Consider we're developing a feature that involves consuming data from the JSON Placeholder API. The feature requires fetching posts and the details of the authors of these posts.  Here's an illustration of how this might typically be implemented:  ","version":"Next","tagName":"h2"},{"title":"Fetching Posts​","type":1,"pageTitle":"Tackling N + 1","url":"/docs/guides/n+1/#fetching-posts","content":" First, we send a request to retrieve all posts:  curl https://jsonplaceholder.typicode.com/posts   The above request fetches a list of posts from the API, each of which includes a userId field indicating the author of the post.  ","version":"Next","tagName":"h3"},{"title":"Fetching Users​","type":1,"pageTitle":"Tackling N + 1","url":"/docs/guides/n+1/#fetching-users","content":" Then, for each post, we need to get the author's details. A request for a specific user might look like this:  curl https://jsonplaceholder.typicode.com/users/1   If we received 100 posts from our first request, we would then make 100 more requests to get each post's author details, resulting in a total of 101 requests.  The N+1 problem, demonstrated using the JSON Placeholder API, refers to the issue where an initial API request generates multiple additional requests. For instance, acquiring 100 posts and then making another request for each post's author details culminates in 101 total requests.  info In real-world applications with thousands of posts and users, this problem intensifies. Each user request can yield hundreds or thousands of additional server requests, stressing server resources, and leading to slower response times, higher server costs, and a degraded user experience. This situation can even lead to server downtime due to the high volume of requests, impacting service availability. Therefore, it's crucial to address the N+1 problem during the design and development of applications involving numerous API requests. Solutions to this issue will be discussed in subsequent sections.  ","version":"Next","tagName":"h3"},{"title":"Using the CLI​","type":1,"pageTitle":"Tackling N + 1","url":"/docs/guides/n+1/#using-the-cli","content":" The TailCall CLI is a potent tool for developers, helping identify N+1 issues in GraphQL applications even before any requests are made or configurations are published in production. This proactive approach allows for potential issues to be mitigated right from the development stage.  Before diving into the usage, ensure you have familiarized yourself with the basics of the TailCall CLI. If you haven't already, please refer to the Installation guide, which will walk you through the setup process and help you understand the key commands.  ","version":"Next","tagName":"h2"},{"title":"Jsonplaceholder Example​","type":1,"pageTitle":"Tackling N + 1","url":"/docs/guides/n+1/#jsonplaceholder-example","content":" Here is a sample .graphql file that we'll be examining:  schema @upstream(baseURL: &quot;http://jsonplaceholder.typicode.com&quot;) { query: Query } type Query { posts: [Post] @http(path: &quot;/posts&quot;) } type User { id: Int! name: String! username: String! email: String! phone: String website: String } type Post { id: Int! userId: Int! title: String! body: String! user: User @http(path: &quot;/users/{{value.userId}}&quot;) }   This schema allows clients to fetch a list of posts, with each post including its associated user data. However, as currently defined, it suffers from the N+1 problem: each post will trigger an additional request to fetch its associated user data.  We will demonstrate how to identify this issue using the TailCall CLI in the next section.  ","version":"Next","tagName":"h3"},{"title":"Running the TailCall CLI​","type":1,"pageTitle":"Tackling N + 1","url":"/docs/guides/n+1/#running-the-tailcall-cli","content":" With the check command, TailCall CLI can assist you in identifying potential N+1 issues in a GraphQL file:  tailcall check ./jsonplaceholder.graphql No errors found. N + 1: 1   The N + 1: 1 line tells you that the TailCall CLI has detected one potential N+1 issue.  For a deeper understanding of these issues, you can use the --n-plus-one-queries parameter:  tailcall check ./jsonplaceholder.graphql --n-plus-one-queries No errors found. N + 1: 1 query { posts { user } }   This parameter uncovers the minimal query that can trigger an N+1 problem. In the above case, query { posts { user } }, represents the minimal query that could lead to an N+1 problem. It illustrates that within the posts query, each post is triggering an additional request to fetch its associated user data.  ","version":"Next","tagName":"h3"},{"title":"Solving Using Batching​","type":1,"pageTitle":"Tackling N + 1","url":"/docs/guides/n+1/#solving-using-batching","content":" Batching is an effective technique to group multiple similar requests into one, substantially reducing the number of server calls. The TailCall CLI provides this capability to address the typical N+1 issue that arises in GraphQL.  To tap into this feature, modify the @http directive on Post.user in your GraphQL schema as follows:  type Post { id: Int! userId: Int! title: String! body: String! user: User @http( path: &quot;/users&quot; query: [{key: &quot;id&quot;, value: &quot;{{value.userId}}&quot;}] groupBy: [&quot;id&quot;] ) }   ","version":"Next","tagName":"h2"},{"title":"Understanding the Update​","type":1,"pageTitle":"Tackling N + 1","url":"/docs/guides/n+1/#understanding-the-update","content":" The described changes introduce significant tweaks to the @http directive and incorporate the @groupBy operator:  query: [{key: &quot;id&quot;, value: &quot;{{value.userId}}&quot;}]: Here, TailCall CLI is instructed to generate a URL where the user id aligns with the userId from the parent Post. For a batch of posts, the CLI compiles a single URL, such as /users?id=1&amp;id=2&amp;id=3...id=10, consolidating multiple requests into one. groupBy: [&quot;id&quot;]: This parameter instructs the system to convert the list of responses into a map internally, using the user's id as the unique key. In essence, it allows the system to differentiate each user value in the response list.  By using this approach, you can reduce the number of requests from 101 (for 100 posts plus one initial request for the post list) to just 2. This significant optimization effectively handles the N+1 problem, thereby enhancing your application's efficiency and user experience. ","version":"Next","tagName":"h3"},{"title":"Watch Mode","type":0,"sectionRef":"#","url":"/docs/guides/watch-mode/","content":"","keywords":"","version":"Next"},{"title":"Use case​","type":1,"pageTitle":"Watch Mode","url":"/docs/guides/watch-mode/#use-case","content":" Running a server in watch mode offers several key benefits:  Real-time Feedback : Watch mode ensures that your server stays up-to-date with your code changes. It immediately reflects those changes, providing you with real-time feedback during development.Efficiency : Manually restarting the server each time you modify code can be tedious and time-consuming. Watch mode automates this process, making development more efficient.Debugging : It helps you quickly identify and fix issues as they arise, reducing the debugging time. When your server automatically restarts upon code changes, you catch errors sooner.  ","version":"Next","tagName":"h2"},{"title":"Using entr​","type":1,"pageTitle":"Watch Mode","url":"/docs/guides/watch-mode/#using-entr","content":" entr is a powerful file-watching utility that makes running a server in watch mode a breeze. Let's go through the steps for the installation process for different operating system :  ","version":"Next","tagName":"h2"},{"title":"Installation​","type":1,"pageTitle":"Watch Mode","url":"/docs/guides/watch-mode/#installation","content":" Homebrew​  Open the Terminal, which you can find in the &quot;Utilities&quot; folder within the &quot;Applications&quot; folder. Install Homebrew if you haven't already. Run the following command in your Terminal: /bin/bash -c &quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install.sh)&quot; Once Homebrew is installed, you can install entr by running the following command: brew install entr To verify the installation, run: entr --version   If the installation is done correctly it will shown the latest version of the entr  Windows Subsystem​  Install Windows Subsystem for Linux (WSL) on your Windows machine by following Microsoft's official documentation. After setting up WSL, open the Linux terminal by running: wsl -d &lt;DistributionName&gt; Replace &lt;DistributionName&gt; with the name of the Linux distribution that you have installed. Install entr within the Linux terminal using the package manager of your chosen Linux distribution. For example, on Ubuntu, you can use: sudo apt update sudo apt install entr Verify the installation by running: entr --version   If the installation is done correctly it will shown the latest version of the entr  apt-get​  On Linux, you can install entr using your distribution's package manager. For example, on Ubuntu, use: sudo apt update sudo apt install entr To verify the installation, run: entr --version   If the installation is done correctly it will shown the latest version of the entr  ","version":"Next","tagName":"h3"},{"title":"Watch Mode​","type":1,"pageTitle":"Watch Mode","url":"/docs/guides/watch-mode/#watch-mode","content":" To run your server in watch mode using entr, you'll utilize the ls command to list the files you want to monitor. The general syntax is as follows:  ls *.graphql | entr -r tailcall start ./jsonplaceholder.graphql   This command uses entr to continuously monitor the jsonplaceholder.graphql file and when it changes, It runs the tailcall start command with the file as an argument  The above command is described in detail below :  ls *.graphql : This part of the code lists the file or files you want to monitor for changes. In this case, it lists the file named &quot;jsonplaceholder.graphql&quot; within the &quot;examples&quot; directory. | : The pipe symbol ('|') is used to take the output of the preceding command (the file listing) and feed it as input to the following command (entr). entr -r tc start ./jsonplaceholder.graphql : This is the command that will be executed whenever the file &quot;jsonplaceholder.graphql&quot; changes.  entr is a command-line tool for running arbitrary commands whenever files change. It monitors the files specified in the previous command (ls ./jsonplaceholder.graphql) r : This flag tells entr to continue running the command even if it encounters errors (it runs the command repeatedly). tc start ./jsonplaceholder.graphql : This is the command to run when changes are detected. It is executing a command tc start with the file path./jsonplaceholder.graphql as an argument  ","version":"Next","tagName":"h3"},{"title":"Some Best Practices​","type":1,"pageTitle":"Watch Mode","url":"/docs/guides/watch-mode/#some-best-practices","content":" To make the most of running a server in watch mode with entr, consider the following best practices:  Selective File Watching: Be selective about which files you monitor with entr. Watching unnecessary files can lead to increased CPU and memory usage. Focus on the essential files related to your project. Organize Your Project: Maintain a well-organized project structure to make it easier to identify which files need monitoring. Clear Output: Clear the terminal output before running entr to have a clean workspace. Version Control: Ensure that your project is under version control (e.g., Git) to track changes and easily revert if necessary. Update entr: Keep entr up to date with the latest version to benefit from bug fixes and improvements.  By following these best practices and using entr effectively, you can significantly improve your development workflow. Experiment with entr, adapt it to your project's specific requirements, and enjoy a smoother and more efficient development process. Happy coding! ","version":"Next","tagName":"h2"},{"title":"@cache","type":0,"sectionRef":"#","url":"/docs/operators/cache/","content":"","keywords":"","version":"Next"},{"title":"maxAge​","type":1,"pageTitle":"@cache","url":"/docs/operators/cache/#maxage","content":" the parameter maxAge takes a non-zero unsigned integer value which signifies the duration, in milliseconds, for which the value will be cached.  In the above example, the entire result of posts query will be cached for 3000ms. When the @cache operator is applied to a type, it is equivalent to applying it to each field individually. If for a type, one of the fields needs to be cached differently then this operator can be applied to that field separately and it will override the values provided for the type, as can be seen in the above example for name field in the User type.  How does the caching work?  If @cache is set for a query or a field, the resolver for it will run once and the result will be stored in memory for maxAge milliseconds, and will expire after this duration. After the cache expires, the resolver will be run again to fetch the latest value and that value will then be cached. ","version":"Next","tagName":"h2"},{"title":"@const","type":0,"sectionRef":"#","url":"/docs/operators/const/","content":"@const The @const operators allows us to embed a constant response for the schema. For eg: schema { query: Query } type Query { user: User @const(data: {name: &quot;John&quot;, age: 12}) } type User { name: String age: Int } The const operator will also validate the provided value at compile time to make sure that it matches the of the field. If the schema of the provided value doesn't match the type of the field, a descriptive error message is show on the console.","keywords":"","version":"Next"},{"title":"@addField","type":0,"sectionRef":"#","url":"/docs/operators/add-field/","content":"@addField The @addField operator simplifies data structures and queries by adding a field that inline or flattens a nested field or node within your schema. It works by modifying the schema and the data transformation process, simplifying how nested data is accessed and presented. For instance, consider a schema: schema { query: Query } type User @addField(name: &quot;street&quot;, path: [&quot;address&quot;, &quot;street&quot;]) { id: Int! name: String! username: String! email: String! phone: String website: String address: Address @modify(omit: true) } type Address { street: String! city: String! state: String! } type Query { user(id: Int!): User @http(path: &quot;/users/{{args.id}}&quot;) } Suppose we are only interested in the street field in Address. The @addField operator above, applied to the User type in this case, creates a field called street in the User type. It includes a path argument, indicating the chain of fields to be traversed from a declared field (address in this case), to the field within Address to be added. We can also add a @modify(omit: true) to omit the address field from the schema, since we have already made its street field available on the User type. Post application, the schema becomes: schema { query: Query } type User { id: Int! name: String! username: String! email: String! phone: String website: String street: String } type Query { user(id: Int): Post! } In the above example, since we added a @modify(omit: true) on the address field, the Address type is eliminated from the schema. The @addField operator also take cares of nullablity of the fields. If any of the fields in the path is nullable, the resulting type will be nullable. Additionally, @addField supports indexing, meaning you can specify the array index to be inlined. If a field posts is of type [Post], and you want to, for example, get the title of the first post, you can specify the path as [&quot;posts&quot;,&quot;0&quot;,&quot;title&quot;]. type User @addField(name: &quot;firstPostTitle&quot;, path: [&quot;posts&quot;, &quot;0&quot;, &quot;title&quot;]) { id: Int! name: String! username: String! email: String! phone: String website: String posts: Post @http(path: &quot;/users/{{value.id}}/posts&quot;) } type Post { id: Int! userId: Int! title: String! body: String! } In conclusion, the @addField operator helps tidy up your schema and streamline data fetching by reducing query depth, promoting better performance and simplicity.","keywords":"","version":"Next"},{"title":"@graphQL","type":0,"sectionRef":"#","url":"/docs/operators/graphql/","content":"","keywords":"","version":"Next"},{"title":"@graphQL​","type":1,"pageTitle":"@graphQL","url":"/docs/operators/graphql/#graphql","content":" The @graphQL operator allows to specify GraphQL API server request to fetch data from.  type Query { users: [User] @graphQL(name: &quot;userList&quot;) }   In this example, the @graphQL operator is used to fetch list of users from the GraphQL API upstream. The name argument is used to specify the name of the root field on the upstream server. The inner fields from the User type to request are inferred from the upcoming request to the Tailcall server. The operation type of the query is inferred from the Tailcall config based on inside which operation type the @graphQL operator is used.  For next request with the config above:  query { users { id name } }   Tailcall will request next query for the upstream:  query { userList { id name } }   ","version":"Next","tagName":"h2"},{"title":"baseURL​","type":1,"pageTitle":"@graphQL","url":"/docs/operators/graphql/#baseurl","content":" This refers to the base URL of the API. If not specified, the default base URL is the one specified in the @upstream operator.  type Query { users: [User] @graphQL(name: &quot;users&quot;, baseURL: &quot;https://graphqlzero.almansi.me/api&quot;) }   ","version":"Next","tagName":"h3"},{"title":"name​","type":1,"pageTitle":"@graphQL","url":"/docs/operators/graphql/#name","content":" Name of the root field on the upstream to request data from. For example:  type Query { users: [User] @graphQL(name: &quot;userList&quot;) }   When Tailcall receives query for users field it will request query for userList from the upstream.  ","version":"Next","tagName":"h3"},{"title":"args​","type":1,"pageTitle":"@graphQL","url":"/docs/operators/graphql/#args","content":" Named arguments for the requested field. For example:  type Query { user: User @graphQL(name: &quot;user&quot;, args: [{key: &quot;id&quot;, value: &quot;{{value.userId}}&quot;}]) }   Will request next query from the upstream for first user's name:  query { user(id: 1) { name } }   ","version":"Next","tagName":"h3"},{"title":"headers​","type":1,"pageTitle":"@graphQL","url":"/docs/operators/graphql/#headers","content":" The headers parameter allows you to customize the headers of the GraphQL request made by the @graphQL operator. It is used by specifying a key-value map of header names and their values.  For instance:  type Mutation { users: User @graphQL(name: &quot;users&quot;, headers: [{key: &quot;X-Server&quot;, value: &quot;Tailcall&quot;}]) }   In this example, a request to /users will include an additional HTTP header X-Server with the value Tailcall.  ","version":"Next","tagName":"h3"},{"title":"batch​","type":1,"pageTitle":"@graphQL","url":"/docs/operators/graphql/#batch","content":" In case upstream GraphQL server supports request batching we can specify argument batch to batch several requests to single upstream into single batch request. For example:  schema @upstream(batch: {maxSize: 1000, delay: 10, headers: [&quot;X-Server&quot;, &quot;Authorization&quot;]}) { query: Query mutation: Mutation } type Query { users: [User] @graphQL(name: &quot;users&quot;, batch: true) posts: [Post] @graphQL(name: &quot;posts&quot;, batch: true) }   Make sure you have also specified batch settings to the @upstream and to the @graphQL operator. ","version":"Next","tagName":"h3"},{"title":"@modify","type":0,"sectionRef":"#","url":"/docs/operators/modify/","content":"","keywords":"","version":"Next"},{"title":"name​","type":1,"pageTitle":"@modify","url":"/docs/operators/modify/#name","content":" You can rename a field or a node in your GraphQL schema using the name argument in the @modify operator. This can be helpful when the field name in your underlying data source doesn't match the desired field name in your schema. For instance:  type User { id: Int! @modify(name: &quot;userId&quot;) }   @modify(name: &quot;userId&quot;) tells GraphQL that although the field is referred to as idin the underlying data source, it should be presented as userId in your schema.  ","version":"Next","tagName":"h2"},{"title":"omit​","type":1,"pageTitle":"@modify","url":"/docs/operators/modify/#omit","content":" You can exclude a field or a node from your GraphQL schema using the omit argument in the @modify operator. This can be useful if you want to keep certain data hidden from the client. For instance:  type User { id: Int! @modify(omit: true) }   @modify(omit: true) tells GraphQL that the id field should not be included in the schema, thus it won't be accessible to the client. ","version":"Next","tagName":"h2"},{"title":"@http","type":0,"sectionRef":"#","url":"/docs/operators/http/","content":"","keywords":"","version":"Next"},{"title":"baseURL​","type":1,"pageTitle":"@http","url":"/docs/operators/http/#baseurl","content":" This refers to the base URL of the API. If not specified, the default base URL is the one specified in the @upstream operator.  type Query { users: [User] @http(path: &quot;/users&quot;, baseURL: &quot;https://jsonplaceholder.typicode.com&quot;) }   ","version":"Next","tagName":"h2"},{"title":"path​","type":1,"pageTitle":"@http","url":"/docs/operators/http/#path","content":" This refers to the API endpoint you're going to call. For instance https://jsonplaceholder.typicode.com/users`.  type Query { users: [User] @http(path: &quot;/users&quot;) }   If your API endpoint contains dynamic segments, you can use Mustache templates to substitute variables. For example, to fetch a specific user, the path can be written as /users/{{args.id}}.  type Query { user(id: ID!): User @http(path: &quot;/users/{{args.id}}&quot;) }   ","version":"Next","tagName":"h2"},{"title":"method​","type":1,"pageTitle":"@http","url":"/docs/operators/http/#method","content":" This refers to the HTTP method of the API call. Commonly used methods include GET, POST, PUT, DELETE, etc. If not specified, the default method is GET. For example:  type Mutation { createUser(input: UserInput!): User @http(method: &quot;POST&quot;, path: &quot;/users&quot;) }   ","version":"Next","tagName":"h2"},{"title":"query​","type":1,"pageTitle":"@http","url":"/docs/operators/http/#query","content":" This represents the query parameters of your API call. You can pass it as a static object or use Mustache template for dynamic parameters. These parameters will be added to the URL. For example:  type Query { userPosts(id: ID!): [Post] @http(path: &quot;/posts&quot;, query: [{key: &quot;userId&quot;, value: &quot;{{args.id}}&quot;}]) }   ","version":"Next","tagName":"h2"},{"title":"body​","type":1,"pageTitle":"@http","url":"/docs/operators/http/#body","content":" The body of the API call. It's used for methods like POST or PUT that send data to the server. You can pass it as a static object or use a Mustache template to substitute variables from the GraphQL variables. For example:  type Mutation { createUser(input: UserInput!): User @http(method: &quot;POST&quot;, path: &quot;/users&quot;, body: &quot;{{args.input}}&quot;) }   In the example above, the createUser mutation sends a POST request to /users, with the input object converted to JSON and included in the request body.  ","version":"Next","tagName":"h2"},{"title":"headers​","type":1,"pageTitle":"@http","url":"/docs/operators/http/#headers","content":" The headers parameter allows you to customize the headers of the HTTP request made by the @http operator. It is used by specifying a key-value map of header names and their values.  For instance:  type Mutation { createUser(input: UserInput!): User @http(path: &quot;/users&quot;, headers: [{key: &quot;X-Server&quot;, value: &quot;Tailcall&quot;}]) }   In this example, a request to /users will include an additional HTTP header X-Server with the value Tailcall.  You can make use of mustache templates to provide dynamic values for headers, derived from the arguments or context provided in the request. For example:  type Mutation { users(name: String): User @http(path: &quot;/users&quot;, headers: [{key: &quot;X-Server&quot;, value: &quot;Tailcall&quot;}, {key: &quot;User-Name&quot;, value: &quot;{{args.name}}&quot;}]) }   In this scenario, the User-Name header's value will dynamically adjust according to the name argument passed in the request.  ","version":"Next","tagName":"h2"},{"title":"groupBy​","type":1,"pageTitle":"@http","url":"/docs/operators/http/#groupby","content":" The groupBy parameter groups multiple data requests into a single call. For more details please refer out n + 1 guide.  type Post { id: Int! name: String! user: User @http(path: &quot;/users&quot;, query: [{key: &quot;id&quot;, value: &quot;{{value.userId}}&quot;}], groupBy: [&quot;id&quot;]) }   query: {key: &quot;id&quot;, value: &quot;{{value.userId}}&quot;}]: Here, TailCall CLI is instructed to generate a URL where the user id aligns with the userId from the parent Post. For a batch of posts, the CLI compiles a single URL, such as /users?id=1&amp;id=2&amp;id=3...id=10, consolidating multiple requests into one. ","version":"Next","tagName":"h2"},{"title":"@grpc","type":0,"sectionRef":"#","url":"/docs/operators/grpc/","content":"","keywords":"","version":"Next"},{"title":"Using the @grpc Operator​","type":1,"pageTitle":"@grpc","url":"/docs/operators/grpc/#using-the-grpc-operator","content":" The @grpc operator allows GraphQL fields to be resolved using gRPC services. Here's an example demonstrating its usage in a GraphQL schema:  type Query { users: [User] @grpc(service: &quot;UserService&quot;, method: &quot;ListUsers&quot;, protoPath: &quot;./proto/user_service.proto&quot;) }   In this example, when the users field is queried, the GraphQL server will make a gRPC request to the ListUsers method of the UserService.  ","version":"Next","tagName":"h3"},{"title":"Sample proto File​","type":1,"pageTitle":"@grpc","url":"/docs/operators/grpc/#sample-proto-file","content":" The .proto file defines the structure of the gRPC service and its methods. Here is a simplified example:  syntax = &quot;proto3&quot;; service UserService { rpc ListUsers (UserListRequest) returns (UserListReply) {} rpc GetUser (UserGetRequest) returns (UserGetReply) {} } message UserListRequest { // Request parameters } message UserListReply { // Reply structure } message UserGetRequest { // Reply structure } message UserGetReply { // Reply structure }   ","version":"Next","tagName":"h3"},{"title":"service​","type":1,"pageTitle":"@grpc","url":"/docs/operators/grpc/#service","content":" Indicates the gRPC service to be called. This should match the service name as defined in the .proto file.  type Query { users: [User] @grpc( service: &quot;UserService&quot; method: &quot;ListUsers&quot; protoPath: &quot;./proto/user_service.proto&quot; ) }   ","version":"Next","tagName":"h3"},{"title":"method​","type":1,"pageTitle":"@grpc","url":"/docs/operators/grpc/#method","content":" Indicates the specific gRPC method to be invoked within the specified service. This should match the method name as defined in the .proto file.  type Query { users: [User] @grpc( service: &quot;UserService&quot; method: &quot;ListUsers&quot; protoPath: &quot;./proto/user_service.proto&quot; ) }   ","version":"Next","tagName":"h3"},{"title":"protoPath​","type":1,"pageTitle":"@grpc","url":"/docs/operators/grpc/#protopath","content":" Path to the .proto file, containing service and method definitions for request/response encoding and decoding. The path can be relative or absolute. If the path is relative, it is resolved relative to the directory where the tailcall command is run from.  type Query { users: [User] @grpc( service: &quot;UserService&quot; method: &quot;ListUsers&quot; protoPath: &quot;./proto/user_service.proto&quot; ) }   ","version":"Next","tagName":"h3"},{"title":"baseURL​","type":1,"pageTitle":"@grpc","url":"/docs/operators/grpc/#baseurl","content":" Indicates the base URL for the gRPC API. If omitted, the default URL defined in the @upstream operator is used.  type Query { users: [User] @grpc( service: &quot;UserService&quot; method: &quot;ListUsers&quot; protoPath: &quot;./proto/user_service.proto&quot; baseURL: &quot;https://grpc-server.example.com&quot; ) }   ","version":"Next","tagName":"h3"},{"title":"body​","type":1,"pageTitle":"@grpc","url":"/docs/operators/grpc/#body","content":" Outlines the arguments for the gRPC call. The body field is used to specify the arguments for the gRPC call. It can be static or dynamic. Here's an example:  type UserInput { id: ID } type Query { user(id: UserInput!): User @grpc( service: &quot;UserService&quot; method: &quot;GetUser&quot; protoPath: &quot;./proto/user_service.proto&quot; body: &quot;{{args.id}}&quot; ) }   ","version":"Next","tagName":"h3"},{"title":"headers​","type":1,"pageTitle":"@grpc","url":"/docs/operators/grpc/#headers","content":" Custom headers for the gRPC request can be specified using the headers argument. This is particularly useful for passing authentication tokens or other contextual information.  type Query { users: [User] @grpc( service: &quot;UserService&quot; method: &quot;ListUsers&quot; protoPath: &quot;./proto/user_service.proto&quot; baseURL: &quot;https://grpc-server.example.com&quot; headers: [{key: &quot;X-CUSTOM-HEADER&quot;, value: &quot;custom-value&quot;}] ) }   ","version":"Next","tagName":"h3"},{"title":"groupBy​","type":1,"pageTitle":"@grpc","url":"/docs/operators/grpc/#groupby","content":" The groupBy argument is used to optimize batch requests by grouping them based on specified response keys. This can significantly improve performance in scenarios with multiple, similar requests.  For using the groupBy capability, the response type of the gRPC method should be a list of objects. For example, if the response type of the gRPC method is UserListReply, then the groupBy argument can be used as follows:  type Query { users(id: UserInput!): User @grpc( service: &quot;UserService&quot; method: &quot;ListUsers&quot; protoPath: &quot;./proto/user_service.proto&quot; baseURL: &quot;https://grpc-server.example.com&quot; groupBy: [&quot;id&quot;] ) }   The @grpc operator is a powerful tool for GraphQL developers, allowing for seamless integration with gRPC services. By understanding and utilizing its various fields, developers can create efficient, streamlined APIs that leverage the strengths of both GraphQL and gRPC. ","version":"Next","tagName":"h3"},{"title":"@upstream","type":0,"sectionRef":"#","url":"/docs/operators/upstream/","content":"","keywords":"","version":"Next"},{"title":"poolIdleTimeout​","type":1,"pageTitle":"@upstream","url":"/docs/operators/upstream/#poolidletimeout","content":" The time in seconds that the connection pool will wait before closing idle connections.  schema @upstream(poolIdleTimeout: 60, baseURL: &quot;http://jsonplaceholder.typicode.com&quot;) { query: Query mutation: Mutation }   ","version":"Next","tagName":"h2"},{"title":"poolMaxIdlePerHost​","type":1,"pageTitle":"@upstream","url":"/docs/operators/upstream/#poolmaxidleperhost","content":" The maximum number of idle connections that will be maintained per host.  schema @upstream(poolMaxIdlePerHost: 60, baseURL: &quot;http://jsonplaceholder.typicode.com&quot;) { query: Query mutation: Mutation }   ","version":"Next","tagName":"h2"},{"title":"keepAliveInterval​","type":1,"pageTitle":"@upstream","url":"/docs/operators/upstream/#keepaliveinterval","content":" The time in seconds between each keep-alive message sent to maintain the connection.  schema @upstream(keepAliveInterval: 60, baseURL: &quot;http://jsonplaceholder.typicode.com&quot;) { query: Query mutation: Mutation }   ","version":"Next","tagName":"h2"},{"title":"keepAliveTimeout​","type":1,"pageTitle":"@upstream","url":"/docs/operators/upstream/#keepalivetimeout","content":" The time in seconds that the connection will wait for a keep-alive message before closing.  schema @upstream(keepAliveTimeout: 60, baseURL: &quot;http://jsonplaceholder.typicode.com&quot;) { query: Query mutation: Mutation }   ","version":"Next","tagName":"h2"},{"title":"keepAliveWhileIdle​","type":1,"pageTitle":"@upstream","url":"/docs/operators/upstream/#keepalivewhileidle","content":" A boolean value that determines whether keep-alive messages should be sent while the connection is idle.  schema @upstream(keepAliveWhileIdle: false, baseURL: &quot;http://jsonplaceholder.typicode.com&quot;) { query: Query mutation: Mutation }   ","version":"Next","tagName":"h2"},{"title":"proxy​","type":1,"pageTitle":"@upstream","url":"/docs/operators/upstream/#proxy","content":" The proxy setting defines an intermediary server through which the upstream requests will be routed before reaching their intended endpoint. By specifying a proxy URL, you introduce an additional layer, enabling custom routing and security policies.  schema @upstream(proxy: {url: &quot;http://localhost:3000&quot;}, baseURL: &quot;http://jsonplaceholder.typicode.com&quot;) { query: Query mutation: Mutation }   In the provided example, we've set the proxy's url to &quot;http://localhost:3000&quot;. This configuration ensures that all requests aimed at the designated baseURL are first channeled through this proxy. To illustrate, if the baseURL is &quot;http://jsonplaceholder.typicode.com&quot;, any request targeting it would be initially sent to &quot;http://localhost:3000&quot; before being redirected to its final destination.  ","version":"Next","tagName":"h2"},{"title":"connectTimeout​","type":1,"pageTitle":"@upstream","url":"/docs/operators/upstream/#connecttimeout","content":" The time in seconds that the connection will wait for a response before timing out.  schema @upstream(connectTimeout: 60, baseURL: &quot;http://jsonplaceholder.typicode.com&quot;) { query: Query mutation: Mutation }   ","version":"Next","tagName":"h2"},{"title":"timeout​","type":1,"pageTitle":"@upstream","url":"/docs/operators/upstream/#timeout","content":" The maximum time in seconds that the connection will wait for a response.  schema @upstream(timeout: 60, baseURL: &quot;http://jsonplaceholder.typicode.com&quot;) { query: Query mutation: Mutation }   ","version":"Next","tagName":"h2"},{"title":"tcpKeepAlive​","type":1,"pageTitle":"@upstream","url":"/docs/operators/upstream/#tcpkeepalive","content":" The time in seconds between each TCP keep-alive message sent to maintain the connection.  schema @upstream(tcpKeepAlive: 60, baseURL: &quot;http://jsonplaceholder.typicode.com&quot;) { query: Query mutation: Mutation }   ","version":"Next","tagName":"h2"},{"title":"userAgent​","type":1,"pageTitle":"@upstream","url":"/docs/operators/upstream/#useragent","content":" The User-Agent header value to be used in HTTP requests.  schema @upstream(userAgent: &quot;Tailcall/1.0&quot;, baseURL: &quot;http://jsonplaceholder.typicode.com&quot;) { query: Query mutation: Mutation }   ","version":"Next","tagName":"h2"},{"title":"allowedHeaders​","type":1,"pageTitle":"@upstream","url":"/docs/operators/upstream/#allowedheaders","content":" The allowedHeaders configuration specifies which HTTP headers are permitted to be forwarded to upstream services when making requests. If allowedHeaders isn't specified, no incoming headers will be forwarded to the upstream services, which can provide an added layer of security but might restrict essential data flow.  schema @upstream(allowedHeaders: [&quot;Authorization&quot;, &quot;X-Api-Key&quot;]) { query: Query mutation: Mutation }   In the example above, the allowedHeaders is set to allow only Authorization and X-Api-Key headers. This means that requests containing these headers will forward them to upstream services, while all others will be ignored. It ensures that only expected headers are communicated to dependent services, emphasizing security and consistency.  ","version":"Next","tagName":"h2"},{"title":"baseURL​","type":1,"pageTitle":"@upstream","url":"/docs/operators/upstream/#baseurl","content":" This refers to the default base URL for your APIs. If it's not explicitly mentioned in the @upstream operator, then each @http operator must specify its own baseURL. If neither @upstream nor @http provides a baseURL, it results in a compilation error.  schema @upstream(baseURL: &quot;http://jsonplaceholder.typicode.com&quot;) { query: Query mutation: Mutation }   In this representation, the baseURL is set as http://jsonplaceholder.typicode.com. Thus, all API calls made by @http will prepend this URL to their respective paths.  tip Ensure that your base URL remains free from specific path segments. GOOD: @upstream(baseURL: http://jsonplaceholder.typicode.com)BAD: @upstream(baseURL: http://jsonplaceholder.typicode.com/api)  ","version":"Next","tagName":"h2"},{"title":"httpCache​","type":1,"pageTitle":"@upstream","url":"/docs/operators/upstream/#httpcache","content":" When activated, directs Tailcall to utilize HTTP caching mechanisms. These mechanisms, in accordance with the HTTP Caching RFC, are designed to improve performance by reducing unnecessary data fetches. If left unspecified, this feature defaults to false.  schema @upstream(httpCache: false) { query: Query mutation: Mutation }   ","version":"Next","tagName":"h2"},{"title":"Tips​","type":1,"pageTitle":"@upstream","url":"/docs/operators/upstream/#tips","content":" Only use batching if necessary and other optimization techniques don't resolve performance issues.Use batching judiciously and monitor its impact.Be aware that batching can complicate debugging  ","version":"Next","tagName":"h3"},{"title":"batch​","type":1,"pageTitle":"@upstream","url":"/docs/operators/upstream/#batch","content":" An object that specifies the batch settings, including maxSize (the maximum size of the batch), delay (the delay in milliseconds between each batch), and headers (an array of HTTP headers to be included in the batch).  schema @upstream(batch: {maxSize: 1000, delay: 10, headers: [&quot;X-Server&quot;, &quot;Authorization&quot;]}) { query: Query mutation: Mutation }  ","version":"Next","tagName":"h2"},{"title":"@server","type":0,"sectionRef":"#","url":"/docs/operators/server/","content":"","keywords":"","version":"Next"},{"title":"workers​","type":1,"pageTitle":"@server","url":"/docs/operators/server/#workers","content":" workers sets the number of worker threads the server will use. If not specified, the default value is the number of cores available to the system.  schema @server(workers: 32) { query: Query mutation: Mutation }   In this example, the workers is set to 32. This means that the Tailcall server will use 32 worker threads.  ","version":"Next","tagName":"h2"},{"title":"port​","type":1,"pageTitle":"@server","url":"/docs/operators/server/#port","content":" This refers to the port on which the Tailcall will be running. If not specified, the default port is 8000.  schema @server(port: 8090) { query: Query mutation: Mutation }   In this example, the port is set to 8090. This means that the Tailcall will be accessible at http://localhost:8090.  tip Always lean towards non-standard ports, steering clear of typical ones like 80 or 8080. Ensure your chosen port is unoccupied.  ","version":"Next","tagName":"h2"},{"title":"cacheControlHeader​","type":1,"pageTitle":"@server","url":"/docs/operators/server/#cachecontrolheader","content":" The cacheControlHeader configuration, when activated, instructs Tailcall to transmit Cache-Control headers in its responses. The max-age value in the header, is the least of the values in the responses received by tailcall from the upstream services. By default, this is set to false meaning no header is set.  schema @server(cacheControlHeader: true) { query: Query mutation: Mutation }   ","version":"Next","tagName":"h2"},{"title":"graphiql​","type":1,"pageTitle":"@server","url":"/docs/operators/server/#graphiql","content":" The grahiql configuration enables the GraphiQL IDE at the root (/) path within Tailcall. GraphiQL is a built-in, interactive in-browser GraphQL IDE, designed to streamline query development and testing. By default, this feature is turned off.  schema @server(port: 8000, graphiql: true) { query: Query mutation: Mutation }   tip While the GraphiQL interface is a powerful tool for development, it's recommended to disable it in production environments, especially if you're not exposing GraphQL APIs directly to users. This ensures an added layer of security and reduces unnecessary exposure.  ","version":"Next","tagName":"h2"},{"title":"vars​","type":1,"pageTitle":"@server","url":"/docs/operators/server/#vars","content":" This configuration allows you to define local variables that can be leveraged during the server's operations. These variables are particularly handy when you need to store constant configurations, secrets, or other shared information that various operations might require.  schema @server(vars: {key: &quot;apiKey&quot;, value: &quot;YOUR_API_KEY_HERE&quot;}) { query: Query mutation: Mutation } type Query { externalData: Data @http(path: &quot;/external-api/data&quot;, headers: [{key: &quot;Authorization&quot;, value: &quot;Bearer {{vars.apiKey}}&quot;}]) }   In the provided example, a variable named apiKey is set with a placeholder value of &quot;YOUR_API_KEY_HERE&quot;. This configuration implies that whenever Tailcall fetches data from the externalData endpoint, it includes the apiKey in the Authorization header of the HTTP request.  tip Local variables, like apiKey, can be instrumental in securing access to external services or providing a unified place for configurations. Ensure that sensitive information stored this way is well protected and not exposed unintentionally, especially if your Tailcall configuration is publicly accessible.  ","version":"Next","tagName":"h2"},{"title":"introspection​","type":1,"pageTitle":"@server","url":"/docs/operators/server/#introspection","content":" This setting governs whether introspection queries are permitted on the server. Introspection is an intrinsic feature of GraphQL, allowing clients to fetch information about the schema directly. This can be instrumental for tools and client applications to understand the types, fields, and operations available. By default, this setting is enabled (true).  schema @server(introspection: false) { query: Query mutation: Mutation }   tip Although introspection is beneficial during development and debugging stages, it's wise to consider disabling it in production environments. Turning off introspection in live deployments can enhance security by preventing potential attackers from easily discerning the schema and any associated business logic or data structures.  ","version":"Next","tagName":"h2"},{"title":"queryValidation​","type":1,"pageTitle":"@server","url":"/docs/operators/server/#queryvalidation","content":" The queryValidation configuration specifies whether the server should validate incoming GraphQL queries against the defined schema. Validating each query ensures its conformity to the schema, preventing errors from invalid or malformed queries. However, there are situations where you might opt to disable it, notably when seeking to enhance server performance at the cost of such checks. This defaults to false if not specified.  schema @server(queryValidation: true) { query: Query mutation: Mutation }   In the example above, queryValidation is set to true, enabling the validation phase for incoming queries.  tip This should be enabled in dev environment to make sure the queries sent are correct and validated, however in production env, you could consider disabling it for improved performance.  ","version":"Next","tagName":"h2"},{"title":"responseValidation​","type":1,"pageTitle":"@server","url":"/docs/operators/server/#responsevalidation","content":" Tailcall automatically can infer the schema of the http endpoints for you. This information can be used to validate responses that are received from the upstream services. Enabling this setting allows you to perform exactly that. If this is not specified, the default setting for responseValidation is false.  schema @server(responseValidation: true) { query: Query mutation: Mutation }   tip Disabling this setting will offer major performance improvements, but at the potential expense of data.  ","version":"Next","tagName":"h2"},{"title":"responseHeaders​","type":1,"pageTitle":"@server","url":"/docs/operators/server/#responseheaders","content":" The responseHeader is an array of key-value pairs. These headers are added to the response of every request made to the server. This can be useful for adding headers like Access-Control-Allow-Origin to allow cross-origin requests, or some additional headers like X-Allowed-Roles to be used by the downstream services.  schema @server(responseHeaders: [{key: &quot;X-Allowed-Roles&quot;, value: &quot;admin,user&quot;}]) { query: Query mutation: Mutation }   ","version":"Next","tagName":"h2"},{"title":"globalResponseTimeout​","type":1,"pageTitle":"@server","url":"/docs/operators/server/#globalresponsetimeout","content":" The globalResponseTimeout configuration determines the maximum duration a query is allowed to run before it's terminated by the server. Essentially, it acts as a safeguard against long-running queries that could strain resources or pose security concerns.  If not explicitly defined, there might be a system-specific or default value that applies.  schema @server(globalResponseTimeout: 5000) { query: Query mutation: Mutation }   In this given example, the globalResponseTimeout is set to 5000 milliseconds, or 5 seconds. This means any query execution taking longer than this duration will be automatically terminated by the server.  tip It's crucial to set an appropriate response timeout, especially in production environments. This not only optimizes resource utilization but also acts as a security measure against potential denial-of-service attacks where adversaries might run complex queries to exhaust server resources.  ","version":"Next","tagName":"h2"},{"title":"version​","type":1,"pageTitle":"@server","url":"/docs/operators/server/#version","content":" The version of HTTP to be used by the server. If not specified, the default value is HTTP1. The available options are HTTP1 and HTTP2.  schema @server(version: HTTP2) { query: Query mutation: Mutation }   ","version":"Next","tagName":"h2"},{"title":"cert​","type":1,"pageTitle":"@server","url":"/docs/operators/server/#cert","content":" The path to certificate(s) to be used when running the server over HTTP2 (HTTPS). If not specified, the default value is null.  schema @server(cert: &quot;./cert.pem&quot;) { query: Query mutation: Mutation }   tip The certificate can be of any extension, but it's highly recommended to use standards (pem, crt, key).  ","version":"Next","tagName":"h2"},{"title":"key​","type":1,"pageTitle":"@server","url":"/docs/operators/server/#key","content":" The path to key to be used when running the server over HTTP2 (HTTPS). If not specified, the default value is null.  schema @server(key: &quot;./key.pem&quot;) { query: Query mutation: Mutation }   tip The key can be of any extension, but it's highly recommended to use standards (pem, crt, key).  ","version":"Next","tagName":"h2"},{"title":"batchRequests​","type":1,"pageTitle":"@server","url":"/docs/operators/server/#batchrequests","content":" Batching in GraphQL combines multiple requests into one, reducing server round trips.  schema @server( port: 8000 batchRequests: true )   ","version":"Next","tagName":"h2"},{"title":"Trade-offs​","type":1,"pageTitle":"@server","url":"/docs/operators/server/#trade-offs","content":" Batching can improve performance but may introduce latency if one request in the batch takes longer. It also makes network traffic debugging harder. ","version":"Next","tagName":"h3"}],"options":{"highlightResult":true,"id":"default"}}