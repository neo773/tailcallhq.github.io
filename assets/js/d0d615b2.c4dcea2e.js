"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[5051],{3063:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>o,contentTitle:()=>a,default:()=>h,frontMatter:()=>r,metadata:()=>c,toc:()=>l});var s=n(4848),i=n(8453);const r={title:"Batch APIs",sidebar_position:6,description:"Discover how to Tailcall leverages batch APIs to optimize performance and reduce upstream requests in GraphQL applications."},a=void 0,c={id:"n+1/batching",title:"Batch APIs",description:"Discover how to Tailcall leverages batch APIs to optimize performance and reduce upstream requests in GraphQL applications.",source:"@site/docs/n+1/batching.md",sourceDirName:"n+1",slug:"/n+1/batching",permalink:"/docs/n+1/batching",draft:!1,unlisted:!1,editUrl:"https://github.com/tailcallhq/tailcallhq.github.io/tree/develop/docs/n+1/batching.md",tags:[],version:"current",sidebarPosition:6,frontMatter:{title:"Batch APIs",sidebar_position:6,description:"Discover how to Tailcall leverages batch APIs to optimize performance and reduce upstream requests in GraphQL applications."},sidebar:"tutorialSidebar",previous:{title:"N + 1 Checks",permalink:"/docs/n+1/compile-time-check"},next:{title:"Conclusion",permalink:"/docs/n+1/conclusion"}},o={},l=[];function d(e){const t={a:"a",admonition:"admonition",code:"code",em:"em",img:"img",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",...(0,i.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(t.p,{children:(0,s.jsx)(t.img,{alt:"Batched API",src:n(6131).A+"",width:"2360",height:"1125"})}),"\n",(0,s.jsxs)(t.p,{children:["An effective technique to mitigate the N+1 problem is deduplicating similar requests, significantly reducing the number of server calls. We achieved it previously using the ",(0,s.jsx)(t.a,{href:"/docs/directives/upstream#dedupe",children:"dedupe"}),' setting. With Tailcall we can go one step further by giving hints about "batch APIs".']}),"\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)(t.strong,{children:"Batch APIs:"})," Are special APIs that allow us to query multiple things at once. In our case we can pass multiple user Ids as query params, to the ",(0,s.jsx)(t.code,{children:"/users"})," API to resolve many users at once:"]}),"\n",(0,s.jsx)(t.admonition,{type:"tip",children:(0,s.jsxs)(t.p,{children:["Try to hit ",(0,s.jsx)(t.a,{href:"https://jsonplaceholder.typicode.com/users?id=1&id=2",children:"/users?id=1&id=2"})]})}),"\n",(0,s.jsxs)(t.p,{children:["TailCall provides the capability to leverage ",(0,s.jsx)(t.em,{children:"Batch APIs"}),". To utilize this feature, edit the ",(0,s.jsx)(t.code,{children:"@http"})," directive on ",(0,s.jsx)(t.code,{children:"Post.user"})," field in your GraphQL schema as follows:"]}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-graphql",metastring:"{9-10}",children:'type Post {\n  id: Int!\n  userId: Int!\n  title: String!\n  body: String!\n  user: User\n    @http(\n      path: "/users"\n      query: [{key: "id", value: "{{.value.userId}}"}]\n      batchKey: ["id"]\n    )\n}\n'})}),"\n",(0,s.jsxs)(t.p,{children:["The described changes introduce two significant tweaks to the ",(0,s.jsx)(t.code,{children:"@http"})," directive:"]}),"\n",(0,s.jsxs)(t.ol,{children:["\n",(0,s.jsxs)(t.li,{children:["\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.strong,{children:"Addition of a query parameter:"})}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-graphql",metastring:"{6}",children:'type Post {\n  # ...\n  user: User\n    @http(\n      path: "/users"\n      query: [{key: "id", value: "{{.value.userId}}"}]\n      batchKey: ["id"]\n    )\n}\n'})}),"\n",(0,s.jsxs)(t.p,{children:["This configuration generates a URL with the ",(0,s.jsx)(t.code,{children:"userId"})," from the ",(0,s.jsx)(t.code,{children:"Post"})," in the query params. For a batch of users, the CLI compiles a single URL, such as ",(0,s.jsx)(t.code,{children:"/users?id=1&id=2&id=3...id=10"}),", consolidating the 10 requests into one."]}),"\n"]}),"\n",(0,s.jsxs)(t.li,{children:["\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.strong,{children:"Addition of a batchKey:"})}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-graphql",metastring:"{7}",children:'type Post {\n  # ...\n  user: User\n    @http(\n      path: "/users"\n      query: [{key: "id", value: "{{.value.userId}}"}]\n      batchKey: ["id"]\n    )\n}\n'})}),"\n",(0,s.jsxs)(t.p,{children:["This parameter instructs the system to use the user's ",(0,s.jsx)(t.code,{children:"id"}),", in the ",(0,s.jsx)(t.code,{children:"User"})," type, as the unique identifier. This helps in differentiating between users received from the batch API."]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(t.p,{children:"Let's see what the server logs when you now start Tailcall with the updated configuration:"}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-graphql",metastring:"{21-22}",children:'schema\n  @server(port: 8000)\n  @upstream(\n    baseURL: "http://jsonplaceholder.typicode.com"\n  ) {\n  query: Query\n}\n\ntype Query {\n  posts: [Post] @http(path: "/posts")\n}\n\ntype Post {\n  id: Int!\n  userId: Int!\n  title: String!\n  body: String!\n  user: User\n    @http(\n      path: "/users"\n      query: [{key: "id", value: "{{.value.userId}}"}]\n      batchKey: ["id"]\n    )\n}\n\ntype User {\n  id: Int!\n  name: String!\n  username: String!\n  email: String!\n}\n'})}),"\n",(0,s.jsx)(t.p,{children:"Let's start the server as usual and focus on the detected N + 1 issues:"}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-text",metastring:"{3,7}",children:"\u276f tailcall start ./examples/jsonplaceholder.graphql\n  INFO File read: ./examples/jsonplaceholder.graphql ... ok\n  INFO N + 1 detected: 0\n  INFO \ud83d\ude80 Tailcall launched at [0.0.0.0:8000] over HTTP/1.1\n  INFO \ud83c\udf0d Playground: https://tailcall.run/playground/?u=http://127.0.0.1:8000/graphql\n  INFO GET http://jsonplaceholder.typicode.com/posts HTTP/1.1\n  INFO GET http://jsonplaceholder.typicode.com/users?id=1&id=10&id=2&id=3&id=4&id=5&id=6&id=7&id=8&id=9 HTTP/1.1\n"})}),"\n",(0,s.jsx)(t.p,{children:"As you can see there are ZERO N + 1 detected this time! It basically means that irrespective of how large the list of posts is there is a finite number of requests that will be issued in this case that's always going to be TWO. And this is how Tailcall users tackle the N + 1 problem in GraphQL."})]})}function h(e={}){const{wrapper:t}={...(0,i.R)(),...e.components};return t?(0,s.jsx)(t,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}},6131:(e,t,n)=>{n.d(t,{A:()=>s});const s=n.p+"assets/images/n+1-batch-58afcc474377b4eb857892bcfda184fc.png"},8453:(e,t,n)=>{n.d(t,{R:()=>a,x:()=>c});var s=n(6540);const i={},r=s.createContext(i);function a(e){const t=s.useContext(r);return s.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function c(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:a(e.components),s.createElement(r.Provider,{value:t},e.children)}}}]);